{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e7eeae-7491-4c13-b68c-05150a012ff9",
   "metadata": {},
   "source": [
    "# Random Forest With Recursive Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17099ec4-bd9c-44c9-84f3-8432947d7e40",
   "metadata": {},
   "source": [
    "Random Forest with Recursive Feature Elimination (RF-RFE) is a feature selection method that combines Random Forests for ranking feature importance with a systematic elimination process to identify the most predictive features. Random Forests assign importance scores to features based on their contribution to the model's accuracy. Recursive Feature Elimination (RFE) iteratively removes the least important features, retraining the model at each step to evaluate performance. By combining these, RF-RFE selects an optimal subset of features that maximizes model performance, often validated through cross-validation (e.g., RFECV). The code was adapted from https://github.com/NedraMekni/COVID-19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b4fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import math\n",
    "import hashlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm,linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel,RFE,RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,KBinsDiscretizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR,LinearSVR\n",
    "from sklearn import model_selection\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from numpy import transpose\n",
    "from collections.abc import Iterable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9fe559-65d9-46da-804b-3111982b21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "input_dir = \"../../3_train_test_split/\"\n",
    "reduced_features_dir = \"./\"\n",
    "plots_dir = \"plots/\"\n",
    "\n",
    "problem_types = [\"regression\", \"classification\"]\n",
    "seed = 42\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(reduced_features_dir, exist_ok=True)\n",
    "os.makedirs(plots_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8023bb-3d7d-456f-864f-2f6329d83eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a dummy variable for regression\n",
    "def add_dummy_variable(df, y, target_column):\n",
    "    is_imputed = (abs(y - (-np.log(10000 * 1e-9))) < 1e-6).astype(int)\n",
    "    df[\"is_imputed\"] = is_imputed.loc[df.index]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd0654-03ef-4b9c-b649-7595c751e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing regression data...\n"
     ]
    }
   ],
   "source": [
    "for problem_type in problem_types:\n",
    "    print(f\"Processing {problem_type} data...\")\n",
    "\n",
    "    # 1. Read Data\n",
    "    if problem_type == \"regression\":\n",
    "        X = pd.read_csv(os.path.join(input_dir, \"train_reg.csv\")).set_index(\"Molecule ChEMBL ID\")\n",
    "        y = pd.read_csv(os.path.join(input_dir, \"descriptors_all.csv\")).set_index(\"Molecule ChEMBL ID\")[\"-logIC50\"]\n",
    "        model = RandomForestRegressor(n_estimators=50, random_state=seed)\n",
    "        cv = KFold(5)\n",
    "        scoring = \"neg_mean_squared_error\"\n",
    "    elif problem_type == \"classification\":\n",
    "        X = pd.read_csv(os.path.join(input_dir, \"train_class.csv\")).set_index(\"Molecule ChEMBL ID\")\n",
    "        y = pd.read_csv(os.path.join(input_dir, \"descriptors_all.csv\")).set_index(\"Molecule ChEMBL ID\")[\"Potency\"]\n",
    "        model = RandomForestClassifier(n_estimators=50, random_state=seed)\n",
    "        cv = StratifiedKFold(5)\n",
    "        scoring = \"accuracy\"\n",
    "\n",
    "    y_train = y.loc[X.index]\n",
    "\n",
    "    # 2. Apply RFECV\n",
    "    rfecv = RFECV(\n",
    "        estimator=model,\n",
    "        step=20,  # Adjust step size to speed up or refine the process\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        min_features_to_select=1\n",
    "    )\n",
    "    rfecv.fit(X, y_train)\n",
    "\n",
    "    # Optimal number of features\n",
    "    print(f\"Optimal number of features for {problem_type}: {rfecv.n_features_}\")\n",
    "\n",
    "    # Reduced feature set\n",
    "    selected_features = X.columns[rfecv.support_]\n",
    "    print(f\"Selected features ({len(selected_features)}): {list(selected_features)}\")\n",
    "\n",
    "    # 3. Save Reduced Features\n",
    "    for file_path in glob.glob(os.path.join(input_dir, f\"*_{problem_type[:3]}*\")):\n",
    "        # Extract file type (train, test, val)\n",
    "        file_type = os.path.basename(file_path).split(\"_\")[0]\n",
    "\n",
    "        # Read and reduce data\n",
    "        df = pd.read_csv(file_path).set_index(\"Molecule ChEMBL ID\")\n",
    "        reduced_df = df[selected_features].copy()\n",
    "\n",
    "        # Add dummy variable for regression\n",
    "        if problem_type == \"regression\":\n",
    "            reduced_df = add_dummy_variable(reduced_df, y, \"-logIC50\")\n",
    "\n",
    "        # Save reduced features\n",
    "        reduced_df.to_csv(os.path.join(reduced_features_dir, file_type))\n",
    "\n",
    "        print(f\"Saved reduced {file_type} data for {problem_type} to {reduced_features_dir}\")\n",
    "\n",
    "    # 4. Plot Cross-Validation Scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross-validation score\")\n",
    "    plt.plot(\n",
    "        range(1, len(rfecv.cv_results_['mean_test_score']) + 1),\n",
    "        rfecv.cv_results_['mean_test_score']\n",
    "    )\n",
    "    plt.title(f\"RFECV Cross-Validation Scores ({problem_type.capitalize()})\")\n",
    "    plt.savefig(os.path.join(plots_dir, f\"{problem_type}_RFECV_CV_Scores.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Peak score\n",
    "    peak_score = max(rfecv.cv_results_[\"mean_test_score\"])\n",
    "    print(f\"The peak cross-validation score for {problem_type} is: {peak_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
